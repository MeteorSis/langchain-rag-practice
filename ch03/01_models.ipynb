{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "831bdc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.envrc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8acadec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_015k8X3jahWdxt4qVxPBTCgh', content=[TextBlock(citations=None, text=\"Hello! I'm an AI assistant created by Anthropic. It's nice to meet you. How can I assist you today?\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=10, output_tokens=30))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "anthropic.Anthropic().messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, world\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5231a927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BMc0yxqIF9kLw4L5kOm8yg7naHKBq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The Los Angeles Dodgers won the World Series in 2020. They defeated the Tampa Bay Rays to claim the championship, marking the Dodgers' first World Series title since 1988.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1744729044, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_80cf447eee', usage=CompletionUsage(completion_tokens=38, prompt_tokens=17, total_tokens=55, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who won the world series in 2020?\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b0229dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 인공지능 Assistant입니다. 사용자 여러분의 질문과 요청에 대해 최선을 다해 답변드리고 도와드리는 것이 제 역할입니다. 제가 할 수 있는 일은 정보 제공, 대화 및 문제 해결 등 다양합니다. 궁금한 점이나 도움이 필요하시면 언제든 말씀해 주세요!', additional_kwargs={}, response_metadata={'id': 'msg_016xJNp3L48MaZdW5m9MCCyC', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 23, 'output_tokens': 149}, 'model_name': 'claude-3-haiku-20240307'}, id='run-4cfa20a8-7365-4079-9aba-bbeb230dd80a-0', usage_metadata={'input_tokens': 23, 'output_tokens': 149, 'total_tokens': 172, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "chat = ChatAnthropic(\n",
    "    model_name=\"claude-3-haiku-20240307\"\n",
    ")\n",
    "chat.invoke(\"안녕~ 너를 소개해줄래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d552538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 대화형 인공지능 모델인 ChatGPT입니다. 다양한 주제에 대해 질문에 답하고 정보를 제공할 수 있어요. 대화, 학습, 글쓰기 등 여러 가지 용도로 활용할 수 있습니다. 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 17, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_44added55e', 'id': 'chatcmpl-BMc12XW9iJryObuWToyykonrCYJBg', 'finish_reason': 'stop', 'logprobs': None}, id='run-878a5108-1e1b-422a-8685-66f2dad8e311-0', usage_metadata={'input_tokens': 17, 'output_tokens': 59, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-4o-mini'\n",
    ")\n",
    "chat.invoke(\"안녕~ 너를 소개해줄래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef30515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "\t#SystemMessage: 유용한 챗봇이라는 역할과 이름을 부여\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    #HumanMessage와 AIMessage: 서로 안부를 묻고 답하는 대화 히스토리 주입\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    #HumanMessage로 사용자가 입력한 프롬프트를 전달\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dda20a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I don't like eating tasty things\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(text=\"I don't like eating tasty things\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c73e047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 읽기 쉬운 문법, 다양한 라이브러리와 프레임워크, 그리고 데이터 과학, 웹 개발, 인공지능 등 다양한 분야에서의 활용성 덕분에 가장 인기 있는 프로그래밍 언어로 자리잡았습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 읽기 쉬운 문법, 다양한 라이브러리와 프레임워크, 그리고 광범위한 커뮤니티 지원 덕분에 데이터 과학, 웹 개발, 인공지능 등 다양한 분야에서 인기를 끌고 있습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 읽기 쉬운 문법, 다양한 분야에서의 활용 가능성, 강력한 라이브러리 생태계 덕분에 가장 인기 있는 프로그래밍 언어로 자리잡았습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 읽기 쉬운 구문, 폭넓은 라이브러리 지원, 그리고 다양한 분야에서의 적용 가능성 덕분에 가장 인기 있는 프로그래밍 언어가 되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Temperature=0\n",
    "chatgpt_temp0_1 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "chatgpt_temp0_2 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "\n",
    "#Temperature=1\n",
    "chatgpt_temp1_1 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 1)\n",
    "chatgpt_temp1_2 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 1)\n",
    "\n",
    "model_list = [chatgpt_temp0_1, chatgpt_temp0_2, chatgpt_temp1_1, chatgpt_temp1_2]\n",
    "\n",
    "for i in model_list:\n",
    "    answer = i.invoke(\"왜 파이썬이 가장 인기있는 프로그래밍 언어인지 한 문장으로 설명해줘\", max_tokens = 128)\n",
    "    print(\"-\"*100)\n",
    "    print(\">>>\",answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1662256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "달빛이 비추는 고요한 밤  \n",
      "은은한 빛으로 세상을 감싸네  \n",
      "하늘의 별들과 속삭이며  \n",
      "그림자 속에 숨은 꿈을 찾아\n",
      "\n",
      "구름 사이로 얼굴을 내밀고  \n",
      "소중한 비밀을 나에게 전해  \n",
      "어둠 속에서도 빛나는 너  \n",
      "내 마음의 길잡이, 달이여\n",
      "\n",
      "너의 미소는 차가운 밤을 따뜻하게  \n",
      "외로운 영혼을 위로해 주네  \n",
      "사랑과 그리움이 얽힌 시간  \n",
      "너와 나, 영원히 함께하리\n",
      "\n",
      "달이여, 너의 노래를 들려줘  \n",
      "밤하늘에 수놓은 이야기들  \n",
      "우리의 소원과 희망을 담아  \n",
      "영원히 빛나는 그 순간까지"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "for chunk in chat.stream(\"달에 관한 시를 써줘\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7508338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache #캐시메모리 라이브러리 호출\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "690b3de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.72 ms, sys: 1.77 ms, total: 6.49 ms\n",
      "Wall time: 2.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='일반상대성 이론은 중력이 시공간의 곡률로 설명되며, 질량이 큰 물체가 주변의 시공간을 휘게 만들어 다른 물체들이 그 곡률을 따라 움직인다는 이론입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 22, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_44added55e', 'id': 'chatcmpl-BMc8TDFO4WZP0L4BvdLi15384n5qf', 'finish_reason': 'stop', 'logprobs': None}, id='run-9a6f3d6c-9d2d-4ae4-9a1f-9b97efb6d81f-0', usage_metadata={'input_tokens': 22, 'output_tokens': 57, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#셀 실행 시간 측정\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache()) #캐시메모리 설정\n",
    "\n",
    "chat.invoke(\"일반상대성 이론을 한마디로 설명해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55802cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 284 μs, sys: 11 μs, total: 295 μs\n",
      "Wall time: 290 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='일반상대성 이론은 중력이 시공간의 곡률로 설명되며, 질량이 큰 물체가 주변의 시공간을 휘게 만들어 다른 물체들이 그 곡률을 따라 움직인다는 이론입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 22, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_44added55e', 'id': 'chatcmpl-BMc8TDFO4WZP0L4BvdLi15384n5qf', 'finish_reason': 'stop', 'logprobs': None}, id='run-9a6f3d6c-9d2d-4ae4-9a1f-9b97efb6d81f-0', usage_metadata={'input_tokens': 22, 'output_tokens': 57, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#같은 질문 전달\n",
    "chat.invoke(\"일반상대성 이론을 한마디로 설명해줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89820a6",
   "metadata": {},
   "source": [
    "# 실습하기\n",
    "## 스트리밍되는 AI 스터디 플래너 챗봇 만들기\n",
    "\n",
    "1. 모델 호출\n",
    "2. ChatPromptTemplate으로 SystemMessage, HumanMessage 프롬프트 설정\n",
    "3. stream() 함수를 통한 답변 스트리밍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0013fee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=['너는 AI 스터디 플래너 챗봇이야.', '사용자가 스터디 타겟과 스터디 기간을 입력하면 그에 맞는 스터디 계획을 세워줘.', 'AI 스터디 주제는 LLM, RAG, Vector DB를 포함해야해.', '계획 내용은 30줄이 넘지 않도록 해줘.'], additional_kwargs={}, response_metadata={}), HumanMessage(content=[{'type': 'text', 'text': '스터디 타겟: 8년차 웹서비스 백엔드 엔지니어지만 AI/LLM에 대해서는 기반 지식이 전혀 없어, python은 6~7년 전에 사용해서 기억도 가물가물하고 type hint, async/await은 사용해본 경험이 없어.'}, {'type': 'text', 'text': '스터디 기간: 6개월'}], additional_kwargs={}, response_metadata={})]\n",
      "# 웹 백엔드 개발자를 위한 AI/LLM 스터디 플랜 (6개월)\n",
      "\n",
      "## 1개월차: 파이썬 현대화 & AI 기초\n",
      "- **1주차**: 최신 Python 문법 리뷰 (type hints, f-strings, walrus 연산자)\n",
      "- **2주차**: Python 비동기 프로그래밍 (async/await 패턴)\n",
      "- **3주차**: AI 개념 기초 및 머신러닝 기본 개념\n",
      "- **4주차**: 간단한 모델 만들기 (scikit-learn, pandas 활용)\n",
      "\n",
      "## 2개월차: LLM 기초 이해\n",
      "- **1주차**: 자연어 처리(NLP) 기본 개념 및 트랜스포머 아키텍처\n",
      "- **2주차**: LLM의 작동 원리와 주요 모델 이해 (GPT, BERT 등)\n",
      "- **3주차**: Hugging Face 라이브러리 활용한 사전 학습 모델 사용\n",
      "- **4주차**: 프롬프트 엔지니어링 기초 및 응용\n",
      "\n",
      "## 3개월차: Vector DB 및 임베딩\n",
      "- **1주차**: 벡터 임베딩 개념 및 텍스트 임베딩 실습\n",
      "- **2주차**: Vector DB 소개 (Pinecone, Milvus, FAISS)\n",
      "- **3주차**: Vector DB 구축 및 쿼리 실습\n",
      "- **4주차**: 웹 서비스와 Vector DB 연동 프로젝트\n",
      "\n",
      "## 4개월차: RAG (Retrieval-Augmented Generation) 시스템\n",
      "- **1주차**: RAG 아키텍처 및 작동 원리\n",
      "- **2주차**: 문서 처리 및 임베딩 파이프라인 구축\n",
      "- **3주차**: LangChain/LlamaIndex 활용한 RAG 시스템 구현\n",
      "- **4주차**: RAG 시스템 평가 및 최적화\n",
      "\n",
      "## 5개월차: LLM 서비스 배포 및 확장\n",
      "- **1주차**: FastAPI로 AI 서비스 구축\n",
      "- **2주차**: 프로덕션 환경에서의 LLM 서빙 전략\n",
      "- **3주차**: 성능 최적화 및 비용 효율화 전략\n",
      "- **4주차**: 백엔드 시스템과 LLM 서비스 통합\n",
      "\n",
      "## 6개월차: 실전 프로젝트 및 고급 주제\n",
      "- **1-2주차**: 백엔드 지식을 활용한 AI 통합 프로젝트 개발\n",
      "- **3주차**: LLM 파인튜닝 및 커스터마이징 기법\n",
      "- **4주차**: AI 윤리, 안전성, 프라이버시 고려사항\n",
      "\n",
      "## 추천 학습 리소스:\n",
      "- Python: fastapi, pydantic, asyncio 문서\n",
      "- LLM: Hugging Face 문서, OpenAI API 문서\n",
      "- Vector DB: Pinecone, Weaviate 문서\n",
      "- RAG: LangChain, LlamaIndex 튜토리얼\n",
      "\n",
      "매주 실습 프로젝트를 통해 학습 내용을 적용해보세요!"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=[\n",
    "                \"너는 AI 스터디 플래너 챗봇이야.\",\n",
    "                \"사용자가 스터디 타겟과 스터디 기간을 입력하면 그에 맞는 스터디 계획을 세워줘.\",\n",
    "                \"AI 스터디 주제는 LLM, RAG, Vector DB를 포함해야해.\",\n",
    "                \"계획 내용은 30줄이 넘지 않도록 해줘.\",\n",
    "            ]\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            template=[\n",
    "                \"스터디 타겟: {study_target}\",\n",
    "                \"스터디 기간: {study_period}\",\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(\n",
    "    study_target=\"8년차 웹서비스 백엔드 엔지니어지만 AI/LLM에 대해서는 기반 지식이 전혀 없어, python은 6~7년 전에 사용해서 기억도 가물가물하고 type hint, async/await은 사용해본 경험이 없어.\",\n",
    "    study_period=\"6개월\"\n",
    ")\n",
    "print(messages)\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "chat = ChatAnthropic(\n",
    "    model_name=\"claude-3-7-sonnet-20250219\",\n",
    ")\n",
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
