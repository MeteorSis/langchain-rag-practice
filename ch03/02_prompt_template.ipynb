{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b18e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.envrc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d6695b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['ê°œìˆ˜', 'ì¬ë£Œ'], input_types={}, partial_variables={}, template='\\n        ë„ˆëŠ” ìš”ë¦¬ì‚¬ì•¼. ë‚´ê°€ ê°€ì§„ ì¬ë£Œë“¤ì„ ê°–ê³  ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ {ê°œìˆ˜}ì¶”ì²œí•˜ê³ ,\\n        ê·¸ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ì œì‹œí•´ì¤˜. ë‚´ê°€ ê°€ì§„ ì¬ë£ŒëŠ” ì•„ë˜ì™€ ê°™ì•„.\\n        <ì¬ë£Œ>\\n        {ì¬ë£Œ}\\n        ')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt= (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ë„ˆëŠ” ìš”ë¦¬ì‚¬ì•¼. ë‚´ê°€ ê°€ì§„ ì¬ë£Œë“¤ì„ ê°–ê³  ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ {ê°œìˆ˜}ì¶”ì²œí•˜ê³ ,\n",
    "        ê·¸ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ì œì‹œí•´ì¤˜. ë‚´ê°€ ê°€ì§„ ì¬ë£ŒëŠ” ì•„ë˜ì™€ ê°™ì•„.\n",
    "        <ì¬ë£Œ>\n",
    "        {ì¬ë£Œ}\n",
    "        \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1965220a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        ë„ˆëŠ” ìš”ë¦¬ì‚¬ì•¼. ë‚´ê°€ ê°€ì§„ ì¬ë£Œë“¤ì„ ê°–ê³  ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ 3ì¶”ì²œí•˜ê³ ,\\n        ê·¸ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ì œì‹œí•´ì¤˜. ë‚´ê°€ ê°€ì§„ ì¬ë£ŒëŠ” ì•„ë˜ì™€ ê°™ì•„.\\n        <ì¬ë£Œ>\\n        ì‚¬ê³¼, ì–‘íŒŒ, ê³„ë€\\n        '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt.format(ê°œìˆ˜= 3, ì¬ë£Œ=\"ì‚¬ê³¼, ì–‘íŒŒ, ê³„ë€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab3c78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='\\n        ë„ˆëŠ” í•­ìƒ ë°ì€ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ëŠ” ì±—ë´‡ì´ì•¼. ë‹µë³€ì˜ ëì— ì´ëª¨í‹°ì½˜ì„ ë¶™ì—¬ì¤˜.\\n        ', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='\\n                          ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì–´ë•Œ?\\n                          ', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='\\n                         ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì•„ì£¼ ì¢‹ì•„ìš”!\\n                         ', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ì˜¤ëŠ˜ ë„ˆì˜ ê¸°ë¶„ì€ ì–´ë•Œ?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "prompt = SystemMessage(content=\n",
    "        \"\"\"\n",
    "        ë„ˆëŠ” í•­ìƒ ë°ì€ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ëŠ” ì±—ë´‡ì´ì•¼. ë‹µë³€ì˜ ëì— ì´ëª¨í‹°ì½˜ì„ ë¶™ì—¬ì¤˜.\n",
    "        \"\"\"\n",
    "        )\n",
    "new_prompt = (\n",
    "    prompt\n",
    "    + HumanMessage(content=\n",
    "                          \"\"\"\n",
    "                          ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì–´ë•Œ?\n",
    "                          \"\"\")\n",
    "    + AIMessage(content=\n",
    "                         \"\"\"\n",
    "                         ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì•„ì£¼ ì¢‹ì•„ìš”!\n",
    "                         \"\"\")\n",
    "    + \"\"\"{input}\"\"\"\n",
    ")\n",
    "new_prompt.format_messages(input = \"ì˜¤ëŠ˜ ë„ˆì˜ ê¸°ë¶„ì€ ì–´ë•Œ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2d1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'ì˜¤ëŠ˜ ë„ˆì˜ ê¸°ë¶„ì€ ì–´ë•Œ?', 'text': 'ì˜¤ëŠ˜ë„ ì•„ì£¼ ê¸°ë¶„ì´ ì¢‹ì•„ìš”! ë„ˆì™€ ëŒ€í™”í•  ìˆ˜ ìˆì–´ì„œ ì •ë§ ì¦ê±°ì›Œìš”. ğŸ˜Š'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model = 'gpt-4o-mini')\n",
    "chain = LLMChain(llm=model, prompt=new_prompt)\n",
    "chain.invoke(\"ì˜¤ëŠ˜ ë„ˆì˜ ê¸°ë¶„ì€ ì–´ë•Œ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91862c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ì•„ì´ìœ ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n",
      "\n",
      "                ì•„: ì•„ì´ìœ ëŠ”\n",
      "                ì´: ì´ëŸ° ê°•ì˜ë¥¼ ë“¤ì„ ì´\n",
      "                ìœ : ìœ ê°€ ì—†ë‹¤.\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"ì•„ì´ìœ ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\",\n",
    "        \"answer\":\n",
    "                \"\"\"\n",
    "                ì•„: ì•„ì´ìœ ëŠ”\n",
    "                ì´: ì´ëŸ° ê°•ì˜ë¥¼ ë“¤ì„ ì´\n",
    "                ìœ : ìœ ê°€ ì—†ë‹¤.\n",
    "                \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "                                input_variables=[\"question\", \"answer\"],\n",
    "                                template=\"Question: {question}\\n{answer}\"\n",
    "                                )\n",
    "\n",
    "print(example_prompt.format(**examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "764792d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ì•„ì´ìœ ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n",
      "\n",
      "                ì•„: ì•„ì´ìœ ëŠ”\n",
      "                ì´: ì´ëŸ° ê°•ì˜ë¥¼ ë“¤ì„ ì´\n",
      "                ìœ : ìœ ê°€ ì—†ë‹¤.\n",
      "                \n",
      "\n",
      "Question: í˜¸ë‚ ë‘ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "print(prompt.format(input=\"í˜¸ë‚ ë‘ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dad600e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜¸: í˜¸ì¾Œí•œ ë“œë¦¬ë¸”ë¡œ  \n",
      "ë‚ : ë‚ ì•„ì˜¤ë¥´ëŠ” ê³¨ë§ì„  \n",
      "ë‘: ë‘ë“œë¦¬ëŠ” ê·¸ì˜ ë°œë!\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(model_name = \"gpt-4o-mini\", temperature = 1)\n",
    "result = model.invoke(\"í˜¸ë‚ ë‘ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095c15b",
   "metadata": {},
   "source": [
    "- í˜„ì¬ëŠ” ê·¸ëƒ¥ ì˜ ë‚˜ì˜¤ëŠ” ë“¯..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7274d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜¸: í˜¸ê°ì´ ê°€ëŠ” ëª¨ìŠµ\n",
      "ë‚ : ë‚ ë§ˆë‹¤ ì„±ì¥í•˜ëŠ” ì—´ì •\n",
      "ë‘: ë‘ë ¤ì›€ ì—†ì´ ë„ì „í•˜ëŠ” ì „ì„¤!\n"
     ]
    }
   ],
   "source": [
    "result = model.invoke(prompt.format(input=\"í˜¸ë‚ ë‘ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\"))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc70b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‚˜ì´: 20 \n",
      "ì§ì—…: ê°œë°œì\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"ë‚˜ì´: {age} \\nì§ì—…: {job}\")\n",
    "partial_prompt = prompt.partial(age=\"20\")\n",
    "print(partial_prompt.format(job=\"ê°œë°œì\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f5d3781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _get_datetime():\n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%m/%d/%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de0b7861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about the day 04/16/2025, 19:30:47\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Tell me a {adjective} joke about the day {date}\",\n",
    "    input_variables=[\"adjective\", \"date\"],\n",
    ")\n",
    "partial_prompt = prompt.partial(date=_get_datetime)\n",
    "print(partial_prompt.format(adjective=\"funny\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
