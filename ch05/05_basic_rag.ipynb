{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00bae344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.envrc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae68385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#헌법 PDF 파일 로드\n",
    "loader = PyPDFLoader(r\"../data/대한민국헌법(헌법)(제00010호)(19880225).pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "#PDF 파일을 1000자 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "#ChromaDB에 청크들을 벡터 임베딩으로 저장(OpenAI 임베딩 모델 활용)\n",
    "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc7f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT 3.5 모델 선언\n",
    "from langchain import hub\n",
    "import os\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "#Langchain Hub에서 RAG 프롬프트 호출\n",
    "prompt = hub.pull(\"rlm/rag-prompt\", api_key=os.environ[\"LANGSMITH_API_KEY\"])\n",
    "\n",
    "#Retriever로 검색한 유사 문서의 내용을 하나의 string으로 결합\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d38eed62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a10af9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9016ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ffa5a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국회의원의 의무에는 청렴의 의무와 국가이익을 우선하여 양심에 따라 직무를 수행해야 하는 의무가 포함됩니다. 또한, 국회의원은 법률이 정하는 직을 겸할 수 없으며, 직무상 발언과 표결에 대해 국회 외에서 책임을 지지 않습니다. 이 외에도 국회의원의 지위를 남용하여 개인적인 이익을 추구해서는 안 됩니다.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_chain.invoke(\"국회의원의 의무는 뭐야?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31f5aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           +---------------------------------+         \n",
      "           | Parallel<context,question>Input |         \n",
      "           +---------------------------------+         \n",
      "                    **               **                \n",
      "                 ***                   ***             \n",
      "               **                         **           \n",
      "+----------------------+              +-------------+  \n",
      "| VectorStoreRetriever |              | Passthrough |  \n",
      "+----------------------+              +-------------+  \n",
      "                    **               **                \n",
      "                      ***         ***                  \n",
      "                         **     **                     \n",
      "           +----------------------------------+        \n",
      "           | Parallel<context,question>Output |        \n",
      "           +----------------------------------+        \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                  +--------------------+               \n",
      "                  | ChatPromptTemplate |               \n",
      "                  +--------------------+               \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                      +------------+                   \n",
      "                      | ChatOpenAI |                   \n",
      "                      +------------+                   \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                   +-----------------+                 \n",
      "                   | StrOutputParser |                 \n",
      "                   +-----------------+                 \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                +-----------------------+              \n",
      "                | StrOutputParserOutput |              \n",
      "                +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "rag_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1492d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.history import BaseChatMessageHistory, RunnableWithMessageHistory\n",
    "\n",
    "# PDF 파일 로드 및 처리\n",
    "loader = PyPDFLoader(r\"../data/대한민국헌법(헌법)(제00010호)(19880225).pdf\")\n",
    "\n",
    "# 1,000자씩 분할하여 Document 객체 형태로 docs에 저장\n",
    "pages = loader.load_and_split()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "# Chroma 벡터 저장소 설정 및 retriever 생성\n",
    "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings(model='text-embedding-3-small'))\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba1dc1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Define the contextualize question prompt\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce9af523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.', additional_kwargs={}, response_metadata={}), HumanMessage(content='대통령의 임기는 몇년이야?', additional_kwargs={}, response_metadata={}), AIMessage(content='대통령의 임기는 5년입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='국회의원은?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(content='대통령의 임기는 몇년이야?'),\n",
    "    AIMessage(content='대통령의 임기는 5년입니다.')\n",
    "]\n",
    "\n",
    "contextualize_q_prompt.invoke({\"input\":\"국회의원은?\", \"chat_history\" : chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0d253dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 유사 청크\n",
      "법제처                                                            5                                                       국가법령정보센터\n",
      "대한민국헌법\n",
      "③국회의원의 선거구와 비례대표제 기타 선거에 관한 사항은 법률로 정한다.\n",
      " \n",
      "제42조 국회의원의 임기는 4년으로 한다.\n",
      " \n",
      "제43조 국회의원은 법률이 정하는 직을 겸할 수 없다.\n",
      " \n",
      "제44조 ①국회의원은 현\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2번째 유사 청크\n",
      "법제처                                                            5                                                       국가법령정보센터\n",
      "대한민국헌법\n",
      "③국회의원의 선거구와 비례대표제 기타 선거에 관한 사항은 법률로 정한다.\n",
      " \n",
      "제42조 국회의원의 임기는 4년으로 한다.\n",
      " \n",
      "제43조 국회의원은 법률이 정하는 직을 겸할 수 없다.\n",
      " \n",
      "제44조 ①국회의원은 현\n",
      "----------------------------------------------------------------------------------------------------\n",
      "3번째 유사 청크\n",
      "법제처                                                            5                                                       국가법령정보센터\n",
      "대한민국헌법\n",
      "③국회의원의 선거구와 비례대표제 기타 선거에 관한 사항은 법률로 정한다.\n",
      " \n",
      "제42조 국회의원의 임기는 4년으로 한다.\n",
      " \n",
      "제43조 국회의원은 법률이 정하는 직을 겸할 수 없다.\n",
      " \n",
      "제44조 ①국회의원은 현\n",
      "----------------------------------------------------------------------------------------------------\n",
      "4번째 유사 청크\n",
      "법제처                                                            5                                                       국가법령정보센터\n",
      "대한민국헌법\n",
      "③국회의원의 선거구와 비례대표제 기타 선거에 관한 사항은 법률로 정한다.\n",
      " \n",
      "제42조 국회의원의 임기는 4년으로 한다.\n",
      " \n",
      "제43조 국회의원은 법률이 정하는 직을 겸할 수 없다.\n",
      " \n",
      "제44조 ①국회의원은 현\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)\n",
    "result = history_aware_retriever.invoke({\"input\":\"국회의원은?\", \"chat_history\" : chat_history})\n",
    "for i in range(len(result)):\n",
    "    print(f\"{i+1}번째 유사 청크\")\n",
    "    print(result[i].page_content[:250])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7409148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90ad1a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국회의원의 임기는 4년으로 정해져 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "#채팅 히스토리를 적재하기 위한 리스트\n",
    "chat_history = []\n",
    "\n",
    "question = \"대통령의 임기는 몇년이야?\"\n",
    "#첫 질문에 답변하기 위한 rag_chain 실행\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "#첫 질문과 답변을 채팅 히스토리로 저장\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])\n",
    "\n",
    "second_question = \"국회의원은?\"\n",
    "#두번째 질문 입력 시에는 첫번째 질문-답변이 저장된 chat_history가 삽입됨\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ed95e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "#채팅 세션별 기록 저장 위한 Dictionary 선언\n",
    "store = {}\n",
    "\n",
    "#주어진 session_id 값에 매칭되는 채팅 히스토리 가져오는 함수 선언\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "#RunnableWithMessageHistory 모듈로 rag_chain에 채팅 기록 세션별로 자동 저장 기능 추가\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee988c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대통령의 임기는 5년이며, 중임할 수 없습니다.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"대통령의 임기는 몇년이야?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"240510101\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1b65dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'국회의원의 임기는 4년입니다.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"국회의원은?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"240510101\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8de64889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.7.1\n",
      "CUDA를 사용할 수 없습니다.\n",
      "CUDA를 사용할 수 없습니다. CPU를 사용합니다.\n",
      "현재 사용 중인 디바이스: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# PyTorch 버전 확인\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "\n",
    "# CUDA 버전 확인 (CUDA를 사용할 수 있는 경우)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CUDA를 사용할 수 없습니다.\")\n",
    "\n",
    "# CUDA 사용 가능 여부 및 디바이스 설정\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"CUDA를 사용할 수 있습니다. 사용 가능한 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA를 사용할 수 없습니다. CPU를 사용합니다.\")\n",
    "\n",
    "print(f\"현재 사용 중인 디바이스: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dbb953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "옛날 옛적에 우주에서 아주 먼 행성인 플루토니아에 사는 외계인 과학자, 프로페서 블라스트가 있었습니다. 그는 우주의 신비를 풀기 위해 평생을 바쳤죠. 어느 날, 그는 태양계를 여행하는 유랑 우주선단을 만났고, 그 중 한 명인 캡틴 코믹이 그에게 재미있는 농담을 들려주었습니다:\n",
      "\n",
      "\"왜 외계인들은 항상 지구를 방문하려고 하는 걸까요? 왜냐하면 우리 행성이 '지구'라고 불리기 때문이죠!\"\n",
      "\n",
      "프로페서 블라스트는 크게 웃었고, 그 후로 그는 우주에서 가장 멋진 농담으로 이 이야기를 기억했습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOllama(model=\"EEVE-Korean-10.8B:latest\")\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic}에 대한 짧은 농담을 들려주세요. \")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"topic\": \"우주여행\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "569b68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "Chroma().delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff21974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "loader = PyPDFLoader(r\"../data/대한민국헌법(헌법)(제00010호)(19880225).pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "model_name = \"jhgan/ko-sbert-nli\"\n",
    "model_kwargs = {'device': 'cpu'} # or 'cuda' if you have a GPU\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, embedding)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\", api_key=os.environ[\"LANGSMITH_API_KEY\"])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever|format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82d3bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "헌법 제1조 1항은 대한민국의 기본 원칙과 방향을 명시하고 있습니다. 이 조항에는 대한민국임시정부의 법통 계승, 불의에 맞선 4·19 민주이념의 이어짐, 정의, 인도, 동포애를 바탕으로 한 민족 단결 강화, 사회적 폐습 및 불의 타파, 자유민주적 기본질서 확립, 그리고 정치, 경제, 사회, 문화 등 모든 영역에서의 기회 균등과 개인의 능력 최고도 발휘가 포함됩니다."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"헌법 제 1조 1항이 뭐야\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
